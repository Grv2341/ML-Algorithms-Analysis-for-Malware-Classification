#!/usr/bin/env python
# coding: utf-8

# In[1]:


import pandas as pd
import numpy as np
import xlrd
import matplotlib.pyplot as plt
algo=['Decision Tree','Naive Bayes','SGD','K-Nearest','Random Forest','SVM','Logistic Regression']
algo_time=[]
algo_acc=[]
workbook = xlrd.open_workbook('Anomalies.xls')
df=pd.read_excel('Anomalies.xls')
df.head()


# In[2]:


df['malware name'] = pd.factorize(df['malware name'])[0] + 1
data=df[df['malware name']!=10]
X=data.iloc[:,0:7].values
X=np.array(X)
y=np.array(data['malware name'])
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import time
from sklearn.metrics import confusion_matrix
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)


# In[3]:


#Decision Tree
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
index=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]
t1=[]
for i in range(0,20):
    classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)
    start=time.time()
    classifier.fit(X_train, y_train)
    y_pred = classifier.predict(X_test)
    end=time.time()
    cm = confusion_matrix(y_test, y_pred)
    t1.append(end-start);
plt.plot(index, t1, color='blue')
plt.xlabel('Iteration Number')
plt.ylabel('Time')
plt.title('Decision Tree (Time)')
plt.show()
cm


# In[4]:


algo_time.append(sum(t1)/len(t1))
end-start


# In[5]:


from sklearn.metrics import accuracy_score
acc=accuracy_score(y_pred,y_test)
algo_acc.append(acc)
acc


# In[6]:


# Naive Bayes
from sklearn.naive_bayes import GaussianNB
t2=[]
for i in range(0,20):
    start=time.time()
    nb=GaussianNB()
    nb.fit(X_train,y_train)
    y_pred=nb.predict(X_test)
    end=time.time()
    cm = confusion_matrix(y_test, y_pred)
    t2.append(end-start);
plt.plot(index, t2, color='blue')
plt.xlabel('Iteration Number')
plt.ylabel('Time')
plt.title('Naive Bayes (Time)')
plt.show()
cm


# In[7]:


algo_time.append(sum(t2)/len(t2))
end-start


# In[8]:


acc=accuracy_score(y_pred,y_test)
algo_acc.append(acc)
acc


# In[9]:


#Stochastic Gradient Descent
from sklearn.linear_model import SGDClassifier
t3=[]
for i in range(0,20):
    start=time.time()
    sgd=SGDClassifier(loss='modified_huber',shuffle=True,random_state=101)
    sgd.fit(X_train,y_train)
    y_pred=nb.predict(X_test)
    end=time.time()
    t3.append(end-start);
plt.plot(index, t3, color='blue')
plt.xlabel('Iteration Number')
plt.ylabel('Time')
plt.title('Stochastic Gradient Descent (Time)')
plt.show()
cm = confusion_matrix(y_test, y_pred)
cm


# In[10]:


algo_time.append(sum(t3)/len(t3))
end-start


# In[11]:


acc=accuracy_score(y_pred,y_test)
algo_acc.append(acc)
acc


# In[12]:


#K-nearest neighbour
from sklearn.neighbors import KNeighborsClassifier
t4=[]
for i in range(0,20):
    knn=KNeighborsClassifier(n_neighbors=15)
    start=time.time()
    knn.fit(X_train,y_train)
    y_pred=knn.predict(X_test)
    end=time.time()
    t4.append(end-start);
plt.plot(index, t4, color='blue')
plt.xlabel('Iteration Number')
plt.ylabel('Time')
plt.title('K-nearest neighbour (Time)')
plt.show()
cm = confusion_matrix(y_test, y_pred)
cm


# In[13]:


algo_time.append(sum(t4)/len(t4))
end-start


# In[14]:


acc=accuracy_score(y_pred,y_test)
algo_acc.append(acc)
acc


# In[15]:


#Random Forest
from sklearn.ensemble import RandomForestClassifier
t5=[]
for i in range(0,20):
    rf = RandomForestClassifier(n_estimators=10, random_state = 0)
    start=time.time()
    rf.fit(X_train,y_train)
    y_pred = rf.predict(X_test)
    end=time.time()
    t5.append(end-start);
plt.plot(index, t5, color='blue')
plt.xlabel('Iteration Number')
plt.ylabel('Time')
plt.title('Random Forest (Time)')
plt.show()
cm = confusion_matrix(y_test, y_pred)
cm


# In[16]:


algo_time.append(sum(t5)/len(t5))
end-start


# In[17]:


acc=accuracy_score(y_pred,y_test)
algo_acc.append(acc)
acc


# In[18]:


#Support Vector Machine
from sklearn.svm import SVC
t6=[]
for i in range(0,20):
    svm=SVC(kernel='linear',C=0.025,random_state=101)
    start=time.time()
    svm.fit(X_train,y_train)
    y_pred = rf.predict(X_test)
    end=time.time()
    t6.append(end-start);
plt.plot(index, t6, color='blue')
plt.xlabel('Iteration Number')
plt.ylabel('Time')
plt.title('Support Vector Machine (Time)')
plt.show()
cm = confusion_matrix(y_test, y_pred)
cm


# In[19]:


algo_time.append(sum(t6)/len(t6))
end-start


# In[20]:


acc=accuracy_score(y_pred,y_test)
algo_acc.append(acc)
acc


# In[21]:


#Logistic Regression
from sklearn.linear_model import LogisticRegression
t7=[]
for i in range(0,20):
    classifier = LogisticRegression(random_state = 101)
    start=time.time()
    classifier.fit(X_train, y_train)
    y_pred = classifier.predict(X_test)
    end=time.time()
    t7.append(end-start);
plt.plot(index, t7, color='blue')
plt.xlabel('Iteration Number')
plt.ylabel('Time')
plt.title('Logistic Regression (Time)')
plt.show()
cm = confusion_matrix(y_test, y_pred)
cm


# In[22]:


algo_time.append(sum(t6)/len(t6))
end-start


# In[23]:


acc=accuracy_score(y_pred,y_test)
algo_acc.append(acc)
acc


# In[24]:


index = np.arange(len(algo))
plt.bar(index, algo_time)
plt.xlabel('Algorithm', fontsize=10)
plt.ylabel('Time Taken', fontsize=10)
plt.xticks(index, algo, fontsize=10, rotation=60)
plt.title('Time Taken in Execution of each Algorithm')
plt.show()


# In[25]:


plt.bar(index, algo_acc)
plt.xlabel('Algorithm', fontsize=10)
plt.ylabel('Accuracy', fontsize=10)
plt.xticks(index, algo, fontsize=10, rotation=60)
plt.title('Accuracy of each Algorithm')
plt.show()


# In[26]:


index=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]
plt.plot(index, t1, color='g',label='Decision Tree')
plt.plot(index, t2, color='red',label='Naive Bayes')
plt.plot(index, t3, color='blue',label='SGD')
plt.plot(index, t4, color='black',label='K-Nearest')
plt.plot(index, t5, color='c',label='Random Forest')
plt.plot(index, t5, color='m',label='SVM')
plt.plot(index, t7, color='y',label='Logistic Regression')
plt.xlabel('Iteration Number')
plt.ylabel('Time')
plt.title('Decision Tree (Time)')
plt.legend()
plt.show()


# In[ ]:




